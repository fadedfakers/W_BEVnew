import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from torch.utils.data import DataLoader

# è·¯å¾„ hack
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from configs.config import BEVConfig as cfg
from data.dataset import BEVMultiTaskDataset
from models.detector import WBEVFusionNet
from utils.box_ops import decode_boxes, bev_nms

def calculate_iou(pred_mask, gt_mask):
    """
    è®¡ç®—äºŒå€¼åŒ–åçš„ IoU.
    pred_mask: (H, W) float [0, 1]
    gt_mask: (H, W) int {0, 1}
    """
    pred_bin = (pred_mask > 0.5).astype(np.uint8)
    gt_bin = (gt_mask > 0.5).astype(np.uint8)
    
    intersection = (pred_bin & gt_bin).sum()
    union = (pred_bin | gt_bin).sum()
    
    # ç‰¹æ®Šæƒ…å†µå¤„ç†
    if union == 0:
        # å¦‚æœ GT ä¸ºç©ºï¼Œé¢„æµ‹ä¹Ÿä¸ºç©º -> 1.0
        # å¦‚æœ GT ä¸ºç©ºï¼Œé¢„æµ‹ä¸ä¸ºç©º -> 0.0
        return 1.0 if pred_bin.sum() == 0 else 0.0
        
    return intersection / (union + 1e-6)

@torch.no_grad()
def run_full_evaluation(checkpoint_path, data_root):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Initializing model on {device}...")
    model = WBEVFusionNet(cfg).to(device)
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ Error: Checkpoint not found at {checkpoint_path}")
        return

    checkpoint = torch.load(checkpoint_path, map_location=device)
    sd = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
    model.load_state_dict(sd)
    model.eval()
    print(f"âœ… Loaded checkpoint: {checkpoint_path}")

    # ä½¿ç”¨ val split
    dataset = BEVMultiTaskDataset(data_root=data_root, split='val')
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=dataset.collate_fn)

    ious = []
    all_scores = []
    all_matches = [] # 1 for TP, 0 for FP
    total_gts = 0
    nan_count = 0

    print(f"ğŸ Validating {len(dataset)} samples...")
    
    for i, (images, points, targets) in enumerate(tqdm(dataloader)):
        images = images.to(device)
        points_list = [p.to(device) for p in points]
        
        outputs = model(images, points_list)
        
        # --- 1. Segmentation Eval ---
        mask_logit = outputs['mask_pred'][0, 0]
        if torch.isnan(mask_logit).any():
            nan_count += 1
            continue

        pred_mask = torch.sigmoid(mask_logit).cpu().numpy()
        gt_mask = targets[0]['masks'].numpy()
        ious.append(calculate_iou(pred_mask, gt_mask))

        # --- 2. Detection Eval ---
        # Decode boxes
        det_boxes_batch = decode_boxes(outputs, K=100, threshold=0.1)
        det_boxes = det_boxes_batch[0]
        
        # NMS
        keep = bev_nms(det_boxes, iou_threshold=0.3)
        det_boxes = det_boxes[keep].cpu().numpy()

        # Get GT boxes
        gt_boxes = targets[0]['boxes'].numpy() # [x, y, w, l] in Grid
        total_gts += len(gt_boxes)

        # Matching Logic (Greedy)
        matched_gt_indices = set()
        
        # å¯¹é¢„æµ‹æ¡†æŒ‰åˆ†æ•°æ’åº (è™½ç„¶ decode_boxes å·²ç»æ’è¿‡äº†ï¼Œä¿é™©èµ·è§)
        # det_boxes: [x, y, w, l, rot, score, class]
        if len(det_boxes) > 0:
            det_boxes = det_boxes[np.argsort(-det_boxes[:, 5])]

        for det in det_boxes:
            det_x, det_y = det[0], det[1]
            score = det[5]
            
            all_scores.append(score)
            
            is_tp = False
            best_dist = float('inf')
            best_gt_idx = -1
            
            # å¯»æ‰¾æœ€è¿‘çš„æœªåŒ¹é… GT
            for g_idx, gt in enumerate(gt_boxes):
                if g_idx in matched_gt_indices:
                    continue
                
                gt_x, gt_y = gt[0], gt[1]
                # è®¡ç®—ç‰©ç†è·ç¦» (ç±³)
                dist_m = np.sqrt((det_x - gt_x)**2 + (det_y - gt_y)**2) * cfg.VOXEL_SIZE
                
                # è·ç¦»é˜ˆå€¼: 2.0ç±³ (å¯¹äºéšœç¢ç‰©æ£€æµ‹æ¯”è¾ƒåˆç†)
                if dist_m < 2.0 and dist_m < best_dist:
                    best_dist = dist_m
                    best_gt_idx = g_idx
            
            if best_gt_idx != -1:
                is_tp = True
                matched_gt_indices.add(best_gt_idx)
            
            all_matches.append(1 if is_tp else 0)

    # --- Metrics Calculation ---
    
    # mIoU
    mean_iou = np.mean(ious) if len(ious) > 0 else 0.0
    
    # AP (Average Precision)
    all_scores = np.array(all_scores)
    all_matches = np.array(all_matches)
    ap = 0.0
    
    if len(all_scores) > 0 and total_gts > 0:
        # Sort by score high -> low
        sorted_indices = np.argsort(-all_scores)
        all_matches = all_matches[sorted_indices]
        
        # Compute Precision/Recall Curve
        tp_cumsum = np.cumsum(all_matches)
        fp_cumsum = np.cumsum(1 - all_matches)
        
        recalls = tp_cumsum / total_gts
        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
        
        # Smooth P-R Curve (VOC style)
        precisions = np.maximum.accumulate(precisions[::-1])[::-1]
        
        # AUC (Area Under Curve)
        # å¤„ç† x è½´ (recall) é‡å¤ç‚¹
        ap = np.trapz(precisions, recalls) 
        # é˜²æ­¢è´Ÿå€¼ (trapz å¯èƒ½å› ä¸º x è½´é¡ºåºé—®é¢˜å‡ºè´Ÿï¼Œè™½ç„¶è¿™é‡Œ recalls å•è°ƒå¢)
        ap = max(0.0, ap)

    print("\n" + "="*40)
    print(f"ğŸ“Š EVALUATION REPORT")
    print(f"  - Rail mIoU:     {mean_iou*100:.2f} %")
    print(f"  - Obstacle AP:   {ap*100:.2f} %")
    print(f"  - NaN Samples:   {nan_count}")
    print(f"  - Valid Samples: {len(ious)}")
    print("="*40)

if __name__ == "__main__":
    # è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„
    CKPT = "checkpoints/20260113_XXXX/model_best.pth"
    DATA = "/root/autodl-tmp/FOD/data"
    
    # è‡ªåŠ¨æœç´¢æœ€æ–°çš„
    if not os.path.exists(CKPT):
        import glob
        list_of_files = glob.glob('checkpoints/*/*.pth') 
        if list_of_files:
            CKPT = max(list_of_files, key=os.path.getctime)
            print(f"ğŸ” Auto-selected checkpoint: {CKPT}")

    run_full_evaluation(CKPT, DATA)